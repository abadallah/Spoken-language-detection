{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-tfzxcA-4Qg"
      },
      "source": [
        "# **Import Librarys**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SY0Op_XYAlLA"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import seaborn as sns\n",
        "from torch.utils.data import random_split\n",
        "from torchvision import datasets\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JZsQctMTBEjL"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE=64\n",
        "num_epochs=100\n",
        "lr=1e-4\n",
        "class_size=7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "447KGpp3_WF4"
      },
      "source": [
        "# **Load data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "transform = transforms.Compose([transforms.Resize((64,64)), transforms.ToTensor(), ])\n",
        "\n",
        "dataset = datasets.ImageFolder('Images/Mel64_7000', transform=transform)\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [5600, 700, 700])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(val_set, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ar': 0, 'de': 1, 'en': 2, 'es': 3, 'fr': 4, 'it': 5, 'pt': 6}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.class_to_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sI7IQVt__c8"
      },
      "source": [
        "# **VGG16 Class**\n",
        "\n",
        "```\n",
        "vgg16 in pytorch\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "cutORKrP8F-B"
      },
      "outputs": [],
      "source": [
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(VGG16, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU())\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU())\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer8 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "        self.layer9 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "        self.layer10 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer11 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "        self.layer12 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU())\n",
        "        self.layer13 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(7*7*512, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes,))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = self.layer6(out)\n",
        "        out = self.layer7(out)\n",
        "        out = self.layer8(out)\n",
        "        out = self.layer9(out)\n",
        "        out = self.layer10(out)\n",
        "        out = self.layer11(out)\n",
        "        out = self.layer12(out)\n",
        "        out = self.layer13(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok5mamc2E_Hk"
      },
      "source": [
        "# **optimize the hyper-parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2RlSWN5d8GE5"
      },
      "outputs": [],
      "source": [
        "num_classes = 7\n",
        "num_epochs = 100\n",
        "batch_size = 32\n",
        "learning_rate = 0.005\n",
        "\n",
        "model = VGG16(num_classes).to(device)\n",
        "\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
        "\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpZgz959MApz"
      },
      "source": [
        "# **Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LW_mXc_f8GLh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Step [175/175], Loss: 1.6112\n",
            "Accuracy of the network on the 5000 validation images: 40.142857142857146 %\n",
            "Epoch [2/100], Step [175/175], Loss: 1.1454\n",
            "Accuracy of the network on the 5000 validation images: 40.0 %\n",
            "Epoch [3/100], Step [175/175], Loss: 1.1490\n",
            "Accuracy of the network on the 5000 validation images: 42.857142857142854 %\n",
            "Epoch [4/100], Step [175/175], Loss: 1.1260\n",
            "Accuracy of the network on the 5000 validation images: 46.57142857142857 %\n",
            "Epoch [5/100], Step [175/175], Loss: 1.2932\n",
            "Accuracy of the network on the 5000 validation images: 49.857142857142854 %\n",
            "Epoch [6/100], Step [175/175], Loss: 1.4079\n",
            "Accuracy of the network on the 5000 validation images: 49.0 %\n",
            "Epoch [7/100], Step [175/175], Loss: 1.1645\n",
            "Accuracy of the network on the 5000 validation images: 47.285714285714285 %\n",
            "Epoch [8/100], Step [175/175], Loss: 1.1570\n",
            "Accuracy of the network on the 5000 validation images: 49.142857142857146 %\n",
            "Epoch [9/100], Step [175/175], Loss: 1.2229\n",
            "Accuracy of the network on the 5000 validation images: 50.42857142857143 %\n",
            "Epoch [10/100], Step [175/175], Loss: 1.2668\n",
            "Accuracy of the network on the 5000 validation images: 52.57142857142857 %\n",
            "Epoch [11/100], Step [175/175], Loss: 1.3622\n",
            "Accuracy of the network on the 5000 validation images: 54.0 %\n",
            "Epoch [12/100], Step [175/175], Loss: 0.7971\n",
            "Accuracy of the network on the 5000 validation images: 56.714285714285715 %\n",
            "Epoch [13/100], Step [175/175], Loss: 1.1606\n",
            "Accuracy of the network on the 5000 validation images: 58.0 %\n",
            "Epoch [14/100], Step [175/175], Loss: 0.7102\n",
            "Accuracy of the network on the 5000 validation images: 61.57142857142857 %\n",
            "Epoch [15/100], Step [175/175], Loss: 1.0594\n",
            "Accuracy of the network on the 5000 validation images: 59.714285714285715 %\n",
            "Epoch [16/100], Step [175/175], Loss: 0.9604\n",
            "Accuracy of the network on the 5000 validation images: 59.714285714285715 %\n",
            "Epoch [17/100], Step [175/175], Loss: 0.9025\n",
            "Accuracy of the network on the 5000 validation images: 58.857142857142854 %\n",
            "Epoch [18/100], Step [175/175], Loss: 0.6191\n",
            "Accuracy of the network on the 5000 validation images: 64.85714285714286 %\n",
            "Epoch [19/100], Step [175/175], Loss: 0.5367\n",
            "Accuracy of the network on the 5000 validation images: 62.142857142857146 %\n",
            "Epoch [20/100], Step [175/175], Loss: 0.8568\n",
            "Accuracy of the network on the 5000 validation images: 65.85714285714286 %\n",
            "Epoch [21/100], Step [175/175], Loss: 0.7167\n",
            "Accuracy of the network on the 5000 validation images: 64.71428571428571 %\n",
            "Epoch [22/100], Step [175/175], Loss: 0.5225\n",
            "Accuracy of the network on the 5000 validation images: 69.28571428571429 %\n",
            "Epoch [23/100], Step [175/175], Loss: 0.3831\n",
            "Accuracy of the network on the 5000 validation images: 66.0 %\n",
            "Epoch [24/100], Step [175/175], Loss: 0.4675\n",
            "Accuracy of the network on the 5000 validation images: 68.0 %\n",
            "Epoch [25/100], Step [175/175], Loss: 0.7506\n",
            "Accuracy of the network on the 5000 validation images: 67.42857142857143 %\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32md:\\GP\\New folder\\Spoken-language-detection\\MVP\\Mel_Sepc\\VGG16.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GP/New%20folder/Spoken-language-detection/MVP/Mel_Sepc/VGG16.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# Backward and optimize\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GP/New%20folder/Spoken-language-detection/MVP/Mel_Sepc/VGG16.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/GP/New%20folder/Spoken-language-detection/MVP/Mel_Sepc/VGG16.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GP/New%20folder/Spoken-language-detection/MVP/Mel_Sepc/VGG16.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GP/New%20folder/Spoken-language-detection/MVP/Mel_Sepc/VGG16.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mEpoch [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m], Step [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m], Loss: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m'\u001b[39m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GP/New%20folder/Spoken-language-detection/MVP/Mel_Sepc/VGG16.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                \u001b[39m.\u001b[39mformat(epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, num_epochs, i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, total_step, loss\u001b[39m.\u001b[39mitem()))\n",
            "File \u001b[1;32mc:\\Users\\mm\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
            "File \u001b[1;32mc:\\Users\\mm\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "            \n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images, labels, outputs\n",
        "    \n",
        "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0GwwJntMZPl"
      },
      "source": [
        "## **Testing Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ZMscp8eM8GUy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 70 test images: 45.285714285714285 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(70, 100 * correct / total))   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8Ppv1BkNavW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VGG16(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer5): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer6): Sequential(\n",
              "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer7): Sequential(\n",
              "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer8): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer9): Sequential(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer10): Sequential(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer11): Sequential(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer12): Sequential(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer13): Sequential(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (fc1): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (fc2): Sequential(\n",
              "    (0): Linear(in_features=4096, out_features=7, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"vgg16_model.pt\") #SAVES THE TRAINED MODEL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VGG16(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer5): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer6): Sequential(\n",
              "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer7): Sequential(\n",
              "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer8): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer9): Sequential(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer10): Sequential(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer11): Sequential(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer12): Sequential(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer13): Sequential(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (fc1): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (fc2): Sequential(\n",
              "    (0): Linear(in_features=4096, out_features=7, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model = VGG16()\n",
        "# model.load_state_dict(torch.load(\"vgg16_model.pt\")) #loads the trained model\n",
        "# model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PreTrained model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PyTorch\n",
        "from torchvision import transforms, datasets, models\n",
        "import torch\n",
        "from torch import optim, cuda\n",
        "from torch.utils.data import DataLoader, sampler\n",
        "import torch.nn as nn\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "# Data science tools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Image manipulations\n",
        "from PIL import Image\n",
        "# Useful for examining network\n",
        "from torchsummary import summary\n",
        "# Timing utility\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "# Visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "train_on_gpu = cuda.is_available()\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\mm\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\mm\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torchvision.models as models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.vgg16(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Freeze early layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): Dropout(p=0.5, inplace=False)\n",
              "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (4): ReLU(inplace=True)\n",
              "  (5): Dropout(p=0.5, inplace=False)\n",
              "  (6): Sequential(\n",
              "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.4, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=7, bias=True)\n",
              "    (4): LogSoftmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_inputs = model.classifier[6].in_features\n",
        "\n",
        "# Add on classifier\n",
        "model.classifier[6] = nn.Sequential(\n",
        "    nn.Linear(n_inputs, 4096), nn.ReLU(), nn.Dropout(0.4),\n",
        "    nn.Linear(4096, 7), nn.LogSoftmax(dim=1))\n",
        "\n",
        "model.classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "151,070,535 total parameters.\n",
            "16,809,991 training parameters.\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f'{total_params:,} total parameters.')\n",
        "total_trainable_params = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'{total_trainable_params:,} training parameters.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_pretrained_model(model_name):\n",
        "\n",
        "    if model_name == 'vgg16':\n",
        "        model = models.vgg16(pretrained=True)\n",
        "\n",
        "        # Freeze early layers\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "        n_inputs = model.classifier[6].in_features\n",
        "\n",
        "        # Add on classifier\n",
        "        model.classifier[6] = nn.Sequential(\n",
        "            nn.Linear(n_inputs, 4096), nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(4096, 7), nn.LogSoftmax(dim=1))\n",
        "\n",
        "    # # Move to gpu and parallelize\n",
        "    # if train_on_gpu:\n",
        "    #     model = model.to('cuda')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = get_pretrained_model('vgg16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [32, 64, 224, 224]           1,792\n",
            "              ReLU-2         [32, 64, 224, 224]               0\n",
            "            Conv2d-3         [32, 64, 224, 224]          36,928\n",
            "              ReLU-4         [32, 64, 224, 224]               0\n",
            "         MaxPool2d-5         [32, 64, 112, 112]               0\n",
            "            Conv2d-6        [32, 128, 112, 112]          73,856\n",
            "              ReLU-7        [32, 128, 112, 112]               0\n",
            "            Conv2d-8        [32, 128, 112, 112]         147,584\n",
            "              ReLU-9        [32, 128, 112, 112]               0\n",
            "        MaxPool2d-10          [32, 128, 56, 56]               0\n",
            "           Conv2d-11          [32, 256, 56, 56]         295,168\n",
            "             ReLU-12          [32, 256, 56, 56]               0\n",
            "           Conv2d-13          [32, 256, 56, 56]         590,080\n",
            "             ReLU-14          [32, 256, 56, 56]               0\n",
            "           Conv2d-15          [32, 256, 56, 56]         590,080\n",
            "             ReLU-16          [32, 256, 56, 56]               0\n",
            "        MaxPool2d-17          [32, 256, 28, 28]               0\n",
            "           Conv2d-18          [32, 512, 28, 28]       1,180,160\n",
            "             ReLU-19          [32, 512, 28, 28]               0\n",
            "           Conv2d-20          [32, 512, 28, 28]       2,359,808\n",
            "             ReLU-21          [32, 512, 28, 28]               0\n",
            "           Conv2d-22          [32, 512, 28, 28]       2,359,808\n",
            "             ReLU-23          [32, 512, 28, 28]               0\n",
            "        MaxPool2d-24          [32, 512, 14, 14]               0\n",
            "           Conv2d-25          [32, 512, 14, 14]       2,359,808\n",
            "             ReLU-26          [32, 512, 14, 14]               0\n",
            "           Conv2d-27          [32, 512, 14, 14]       2,359,808\n",
            "             ReLU-28          [32, 512, 14, 14]               0\n",
            "           Conv2d-29          [32, 512, 14, 14]       2,359,808\n",
            "             ReLU-30          [32, 512, 14, 14]               0\n",
            "        MaxPool2d-31            [32, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-32            [32, 512, 7, 7]               0\n",
            "           Linear-33                 [32, 4096]     102,764,544\n",
            "             ReLU-34                 [32, 4096]               0\n",
            "          Dropout-35                 [32, 4096]               0\n",
            "           Linear-36                 [32, 4096]      16,781,312\n",
            "             ReLU-37                 [32, 4096]               0\n",
            "          Dropout-38                 [32, 4096]               0\n",
            "           Linear-39                 [32, 4096]      16,781,312\n",
            "             ReLU-40                 [32, 4096]               0\n",
            "          Dropout-41                 [32, 4096]               0\n",
            "           Linear-42                    [32, 7]          28,679\n",
            "       LogSoftmax-43                    [32, 7]               0\n",
            "================================================================\n",
            "Total params: 151,070,535\n",
            "Trainable params: 16,809,991\n",
            "Non-trainable params: 134,260,544\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 18.38\n",
            "Forward/backward pass size (MB): 7003.75\n",
            "Params size (MB): 576.29\n",
            "Estimated Total Size (MB): 7598.42\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(model, input_size=(3, 224, 224), batch_size=32, device=\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Dropout(p=0.2, inplace=False)\n",
            "  (3): Linear(in_features=4096, out_features=7, bias=True)\n",
            "  (4): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model.classifier[6])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0, 'ar'), (1, 'de'), (2, 'en'), (3, 'es'), (4, 'fr'), (5, 'it'), (6, 'pt')]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.class_to_idx = dataset.class_to_idx\n",
        "model.idx_to_class = {\n",
        "    idx: class_\n",
        "    for class_, idx in model.class_to_idx.items()\n",
        "}\n",
        "list(model.idx_to_class.items())[:7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model,criterion,optimizer,train_loader,valid_loader,save_file_name,\n",
        "          max_epochs_stop=3,n_epochs=20,print_every=1):\n",
        "    \"\"\"Train a PyTorch Model\n",
        "\n",
        "    Params\n",
        "    --------\n",
        "        model (PyTorch model): cnn to train\n",
        "        criterion (PyTorch loss): objective to minimize\n",
        "        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n",
        "        train_loader (PyTorch dataloader): training dataloader to iterate through\n",
        "        valid_loader (PyTorch dataloader): validation dataloader used for early stopping\n",
        "        save_file_name (str ending in '.pt'): file path to save the model state dict\n",
        "        max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\n",
        "        n_epochs (int): maximum number of training epochs\n",
        "        print_every (int): frequency of epochs to print training stats\n",
        "\n",
        "    Returns\n",
        "    --------\n",
        "        model (PyTorch model): trained cnn with best weights\n",
        "        history (DataFrame): history of train and validation loss and accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    # Early stopping intialization\n",
        "    epochs_no_improve = 0\n",
        "    valid_loss_min = np.Inf\n",
        "\n",
        "    valid_max_acc = 0\n",
        "    history = []\n",
        "\n",
        "    # Number of epochs already trained (if using loaded in model weights)\n",
        "    try:\n",
        "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
        "    except:\n",
        "        model.epochs = 0\n",
        "        print(f'Starting Training from Scratch.\\n')\n",
        "\n",
        "    overall_start = timer()\n",
        "\n",
        "    # Main loop\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        # keep track of training and validation loss each epoch\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        train_acc = 0\n",
        "        valid_acc = 0\n",
        "\n",
        "        # Set to training\n",
        "        model.train()\n",
        "        start = timer()\n",
        "\n",
        "        # Training loop\n",
        "        for ii, (data, target) in enumerate(train_loader):\n",
        "            # Tensors to gpu\n",
        "            if train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "\n",
        "            # Clear gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Predicted outputs are log probabilities\n",
        "            output = model(data)\n",
        "\n",
        "            # Loss and backpropagation of gradients\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track train loss by multiplying average loss by number of examples in batch\n",
        "            train_loss += loss.item() * data.size(0)\n",
        "\n",
        "            # Calculate accuracy by finding max log probability\n",
        "            _, pred = torch.max(output, dim=1)\n",
        "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "            # Need to convert correct tensor from int to float to average\n",
        "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
        "            # Multiply average accuracy times the number of examples in batch\n",
        "            train_acc += accuracy.item() * data.size(0)\n",
        "\n",
        "            # Track training progress\n",
        "            print(\n",
        "                f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
        "                end='\\r')\n",
        "\n",
        "        # After training loops ends, start validation\n",
        "        else:\n",
        "            model.epochs += 1\n",
        "\n",
        "            # Don't need to keep track of gradients\n",
        "            with torch.no_grad():\n",
        "                # Set to evaluation mode\n",
        "                model.eval()\n",
        "\n",
        "                # Validation loop\n",
        "                for data, target in valid_loader:\n",
        "                    # Tensors to gpu\n",
        "                    if train_on_gpu:\n",
        "                        data, target = data.cuda(), target.cuda()\n",
        "\n",
        "                    # Forward pass\n",
        "                    output = model(data)\n",
        "\n",
        "                    # Validation loss\n",
        "                    loss = criterion(output, target)\n",
        "                    # Multiply average loss times the number of examples in batch\n",
        "                    valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "                    # Calculate validation accuracy\n",
        "                    _, pred = torch.max(output, dim=1)\n",
        "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "                    accuracy = torch.mean(\n",
        "                        correct_tensor.type(torch.FloatTensor))\n",
        "                    # Multiply average accuracy times the number of examples\n",
        "                    valid_acc += accuracy.item() * data.size(0)\n",
        "\n",
        "                # Calculate average losses\n",
        "                train_loss = train_loss / len(train_loader.dataset)\n",
        "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "\n",
        "                # Calculate average accuracy\n",
        "                train_acc = train_acc / len(train_loader.dataset)\n",
        "                valid_acc = valid_acc / len(valid_loader.dataset)\n",
        "\n",
        "                history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
        "\n",
        "                # Print training and validation results\n",
        "                if (epoch + 1) % print_every == 0:\n",
        "                    print(\n",
        "                        f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
        "                    )\n",
        "                    print(\n",
        "                        f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
        "                    )\n",
        "\n",
        "                # Save the model if validation loss decreases\n",
        "                if valid_loss < valid_loss_min:\n",
        "                    # Save model\n",
        "                    torch.save(model.state_dict(), save_file_name)\n",
        "                    # Track improvement\n",
        "                    epochs_no_improve = 0\n",
        "                    valid_loss_min = valid_loss\n",
        "                    valid_best_acc = valid_acc\n",
        "                    best_epoch = epoch\n",
        "\n",
        "                # Otherwise increment count of epochs with no improvement\n",
        "                else:\n",
        "                    epochs_no_improve += 1\n",
        "                    # Trigger early stopping\n",
        "                    if epochs_no_improve >= max_epochs_stop:\n",
        "                        print(\n",
        "                            f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
        "                        )\n",
        "                        total_time = timer() - overall_start\n",
        "                        print(\n",
        "                            f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
        "                        )\n",
        "\n",
        "                        # Load the best state dict\n",
        "                        model.load_state_dict(torch.load(save_file_name))\n",
        "                        # Attach the optimizer\n",
        "                        model.optimizer = optimizer\n",
        "\n",
        "                        # Format history\n",
        "                        history = pd.DataFrame(\n",
        "                            history,\n",
        "                            columns=[\n",
        "                                'train_loss', 'valid_loss', 'train_acc',\n",
        "                                'valid_acc'\n",
        "                            ])\n",
        "                        return model, history\n",
        "\n",
        "    # Attach the optimizer\n",
        "    model.optimizer = optimizer\n",
        "    # Record overall time and print out stats\n",
        "    total_time = timer() - overall_start\n",
        "    print(\n",
        "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
        "    )\n",
        "    print(\n",
        "        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n",
        "    )\n",
        "    # Format history\n",
        "    history = pd.DataFrame(\n",
        "        history,\n",
        "        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4096, 4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([7, 4096])\n",
            "torch.Size([7])\n"
          ]
        }
      ],
      "source": [
        "for p in optimizer.param_groups[0]['params']:\n",
        "    if p.requires_grad:\n",
        "        print(p.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Training from Scratch.\n",
            "\n",
            "Epoch: 0\t100.00% complete. 133.74 seconds elapsed in epoch.\n",
            "Epoch: 0 \tTraining Loss: 1.7192 \tValidation Loss: 1.5761\n",
            "\t\tTraining Accuracy: 31.75%\t Validation Accuracy: 35.86%\n",
            "Epoch: 1\t100.00% complete. 145.17 seconds elapsed in epoch.\n",
            "Epoch: 1 \tTraining Loss: 1.5865 \tValidation Loss: 1.5082\n",
            "\t\tTraining Accuracy: 36.23%\t Validation Accuracy: 39.00%\n",
            "Epoch: 2\t100.00% complete. 132.80 seconds elapsed in epoch.\n",
            "Epoch: 2 \tTraining Loss: 1.5620 \tValidation Loss: 1.5333\n",
            "\t\tTraining Accuracy: 36.95%\t Validation Accuracy: 40.29%\n",
            "Epoch: 3\t100.00% complete. 132.07 seconds elapsed in epoch.\n",
            "Epoch: 3 \tTraining Loss: 1.5312 \tValidation Loss: 1.4390\n",
            "\t\tTraining Accuracy: 38.25%\t Validation Accuracy: 43.29%\n",
            "Epoch: 4\t100.00% complete. 140.58 seconds elapsed in epoch.\n",
            "Epoch: 4 \tTraining Loss: 1.5262 \tValidation Loss: 1.4631\n",
            "\t\tTraining Accuracy: 40.04%\t Validation Accuracy: 38.57%\n",
            "Epoch: 5\t100.00% complete. 140.97 seconds elapsed in epoch.\n",
            "Epoch: 5 \tTraining Loss: 1.5044 \tValidation Loss: 1.4471\n",
            "\t\tTraining Accuracy: 39.30%\t Validation Accuracy: 44.57%\n",
            "Epoch: 6\t100.00% complete. 141.15 seconds elapsed in epoch.\n",
            "Epoch: 6 \tTraining Loss: 1.4926 \tValidation Loss: 1.4538\n",
            "\t\tTraining Accuracy: 39.50%\t Validation Accuracy: 42.57%\n",
            "Epoch: 7\t100.00% complete. 139.27 seconds elapsed in epoch.\n",
            "Epoch: 7 \tTraining Loss: 1.4934 \tValidation Loss: 1.4378\n",
            "\t\tTraining Accuracy: 39.88%\t Validation Accuracy: 42.71%\n",
            "Epoch: 8\t100.00% complete. 139.09 seconds elapsed in epoch.\n",
            "Epoch: 8 \tTraining Loss: 1.4768 \tValidation Loss: 1.4317\n",
            "\t\tTraining Accuracy: 40.57%\t Validation Accuracy: 44.71%\n",
            "Epoch: 9\t100.00% complete. 142.69 seconds elapsed in epoch.\n",
            "Epoch: 9 \tTraining Loss: 1.4698 \tValidation Loss: 1.4471\n",
            "\t\tTraining Accuracy: 40.29%\t Validation Accuracy: 40.29%\n",
            "Epoch: 10\t100.00% complete. 141.21 seconds elapsed in epoch.\n",
            "Epoch: 10 \tTraining Loss: 1.4715 \tValidation Loss: 1.4235\n",
            "\t\tTraining Accuracy: 41.59%\t Validation Accuracy: 42.57%\n",
            "Epoch: 11\t100.00% complete. 141.93 seconds elapsed in epoch.\n",
            "Epoch: 11 \tTraining Loss: 1.4561 \tValidation Loss: 1.4126\n",
            "\t\tTraining Accuracy: 42.00%\t Validation Accuracy: 47.29%\n",
            "Epoch: 12\t100.00% complete. 139.94 seconds elapsed in epoch.\n",
            "Epoch: 12 \tTraining Loss: 1.4679 \tValidation Loss: 1.4310\n",
            "\t\tTraining Accuracy: 41.02%\t Validation Accuracy: 42.43%\n",
            "Epoch: 13\t100.00% complete. 141.00 seconds elapsed in epoch.\n",
            "Epoch: 13 \tTraining Loss: 1.4397 \tValidation Loss: 1.3936\n",
            "\t\tTraining Accuracy: 42.70%\t Validation Accuracy: 45.29%\n",
            "Epoch: 14\t100.00% complete. 140.70 seconds elapsed in epoch.\n",
            "Epoch: 14 \tTraining Loss: 1.4532 \tValidation Loss: 1.3983\n",
            "\t\tTraining Accuracy: 41.93%\t Validation Accuracy: 44.14%\n",
            "Epoch: 15\t100.00% complete. 140.76 seconds elapsed in epoch.\n",
            "Epoch: 15 \tTraining Loss: 1.4270 \tValidation Loss: 1.3854\n",
            "\t\tTraining Accuracy: 43.89%\t Validation Accuracy: 47.57%\n",
            "Epoch: 16\t100.00% complete. 140.71 seconds elapsed in epoch.\n",
            "Epoch: 16 \tTraining Loss: 1.4353 \tValidation Loss: 1.4143\n",
            "\t\tTraining Accuracy: 42.36%\t Validation Accuracy: 44.57%\n",
            "Epoch: 17\t100.00% complete. 141.09 seconds elapsed in epoch.\n",
            "Epoch: 17 \tTraining Loss: 1.4298 \tValidation Loss: 1.3880\n",
            "\t\tTraining Accuracy: 43.23%\t Validation Accuracy: 43.57%\n",
            "Epoch: 18\t100.00% complete. 141.35 seconds elapsed in epoch.\n",
            "Epoch: 18 \tTraining Loss: 1.4359 \tValidation Loss: 1.4010\n",
            "\t\tTraining Accuracy: 42.71%\t Validation Accuracy: 44.57%\n",
            "Epoch: 19\t100.00% complete. 141.17 seconds elapsed in epoch.\n",
            "Epoch: 19 \tTraining Loss: 1.4173 \tValidation Loss: 1.3969\n",
            "\t\tTraining Accuracy: 43.70%\t Validation Accuracy: 43.43%\n",
            "Epoch: 20\t100.00% complete. 141.32 seconds elapsed in epoch.\n",
            "Epoch: 20 \tTraining Loss: 1.4160 \tValidation Loss: 1.3964\n",
            "\t\tTraining Accuracy: 43.61%\t Validation Accuracy: 46.43%\n",
            "\n",
            "Early Stopping! Total epochs: 20. Best epoch: 15 with loss: 1.39 and acc: 46.43%\n",
            "3240.65 total seconds elapsed. 154.32 seconds per epoch.\n"
          ]
        }
      ],
      "source": [
        "model, history = train(\n",
        "    model,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    train_loader,\n",
        "    valid_loader,\n",
        "    save_file_name=\"VGG_Pre2.pt\",\n",
        "    max_epochs_stop=5,\n",
        "    n_epochs=30,\n",
        "    print_every=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_ftrs = model_ft.classifier[0].in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, 7)\n",
        "#model_ft = model_ft.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            epoch_loss = running_loss / 560\n",
        "            epoch_acc = running_corrects.double() / 560\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "            # deep copy the model\n",
        "        print()\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 14.2380 Acc: 0.0000\n",
            "val Loss: 11.1269 Acc: 0.0000\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 10.5690 Acc: 0.0000\n",
            "val Loss: 9.0096 Acc: 0.0000\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 9.0032 Acc: 0.0000\n",
            "val Loss: 8.1372 Acc: 0.0000\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 8.4863 Acc: 0.0000\n",
            "val Loss: 8.0768 Acc: 0.0000\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 8.4173 Acc: 0.0000\n",
            "val Loss: 8.0209 Acc: 0.0000\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 8.4034 Acc: 0.0000\n",
            "val Loss: 7.9673 Acc: 0.0000\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 8.3272 Acc: 0.0000\n",
            "val Loss: 7.9150 Acc: 0.0000\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 8.2990 Acc: 0.0000\n",
            "val Loss: 7.8639 Acc: 0.0000\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 8.2266 Acc: 0.0000\n",
            "val Loss: 7.8143 Acc: 0.0000\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 8.1943 Acc: 0.0000\n",
            "val Loss: 7.7653 Acc: 0.0000\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 8.1486 Acc: 0.0000\n",
            "val Loss: 7.7605 Acc: 0.0000\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 8.1391 Acc: 0.0000\n",
            "val Loss: 7.7558 Acc: 0.0000\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 8.1095 Acc: 0.0000\n",
            "val Loss: 7.7511 Acc: 0.0000\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 8.1145 Acc: 0.0000\n",
            "val Loss: 7.7465 Acc: 0.0000\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 8.0940 Acc: 0.0000\n",
            "val Loss: 7.7418 Acc: 0.0000\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 8.1049 Acc: 0.0000\n",
            "val Loss: 7.7372 Acc: 0.0000\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 8.1337 Acc: 0.0000\n",
            "val Loss: 7.7326 Acc: 0.0000\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 8.0955 Acc: 0.0000\n",
            "val Loss: 7.7323 Acc: 0.0000\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 8.0966 Acc: 0.0000\n",
            "val Loss: 7.7319 Acc: 0.0000\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 8.0558 Acc: 0.0000\n",
            "val Loss: 7.7316 Acc: 0.0000\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 8.0871 Acc: 0.0000\n",
            "val Loss: 7.7312 Acc: 0.0000\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 8.0856 Acc: 0.0000\n",
            "val Loss: 7.7309 Acc: 0.0000\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 8.0945 Acc: 0.0000\n",
            "val Loss: 7.7305 Acc: 0.0000\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 8.0687 Acc: 0.0000\n",
            "val Loss: 7.7302 Acc: 0.0000\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 8.0950 Acc: 0.0000\n",
            "val Loss: 7.7302 Acc: 0.0000\n",
            "\n",
            "Training complete in 20m 23s\n"
          ]
        }
      ],
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 70 test images: 0.0 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model_ft(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(70, 100 * correct / total))   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "dbce3ab015948f9d7a38d0a4c6629e1339f6d90306f3d65fd7273a0ce3b29204"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
